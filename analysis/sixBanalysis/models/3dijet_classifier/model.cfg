[model]
input_parameters = 27
param1_n6 = jet_pt
param2_n6 = jet_eta
param3_n6 = jet_phi
param4_n6 = jet_btag
param5_n6 = boosted_pt
num_hidden_layers = 2
input_activation_function = selu
hidden_layer_nodes = 40,20
hidden_activation_function = selu
num_output_nodes = 2
output_activation_function = Softmax

[training]
optimizer = nadam
learning_rate = 0.001
num_epochs = 200
beta_1 = 0.9
beta_2 = 0.999
epsilon = 1e-07
loss_function = binary_crossentropy
batch_size = 50

[scaler]
scale_min = 20.000044,20.00003,20.000021,20.000053,20.000095,20.000223,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-3.1415837,-3.1415837,-3.1415837,-3.1415837,-3.1415837,-3.1415837,0.0011634827,0.0011281967,0.0012016296,0.0012426376,0.0011119843,0.001168251,0.052840434,5.3223658,12.081648
scale_max = 844.55414,914.4579,1123.5344,1255.331,1750.8777,1802.4725,2.4995117,2.4995117,2.4995117,2.4995117,2.4995117,2.4995117,3.1415837,3.1415837,3.1415837,3.1415837,3.1415837,3.1415837,0.9995117,0.9995117,0.9995117,0.9995117,0.9995117,0.9995117,708.03033,1181.4178,1693.0917

