[model]
input_parameters = 27
param1_n6 = jet_pt
param2_n6 = jet_eta
param3_n6 = jet_phi
param4_n6 = jet_btag
param5_n6 = boosted_pt
num_hidden_layers = 2
input_activation_function = selu
hidden_layer_nodes = 40,20
hidden_activation_function = selu
num_output_nodes = 2
output_activation_function = Softmax

[training]
optimizer = nadam
learning_rate = 0.001
num_epochs = 108
beta_1 = 0.9
beta_2 = 0.999
epsilon = 1e-07
loss_function = binary_crossentropy
batch_size = 50

[scaler]
scale_min = 20.000021,20.000044,20.00003,20.00031,20.000053,20.000084,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-3.1415837,-3.1415837,-3.1415837,-3.1415837,-3.1415837,-3.1415837,0.0011739731,0.0011119843,0.0011634827,0.0011663437,0.0011281967,0.001168251,14.409722,4.061553,0.021531645
scale_max = 1529.801,1802.4725,1220.2538,1255.331,950.9518,725.4127,2.4995117,2.4995117,2.4995117,2.4995117,2.4995117,2.4995117,3.1415837,3.1415837,3.1415837,3.1415837,3.1415837,3.1415837,0.9995117,0.9995117,0.9995117,0.9995117,0.9995117,0.9995117,1752.4949,1275.3312,740.3838

