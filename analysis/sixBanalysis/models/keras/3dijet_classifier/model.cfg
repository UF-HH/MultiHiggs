[model]
input_parameters = 30
param1_n6 = jet_pt
param2_n6 = jet_eta
param3_n6 = jet_phi
param4_n6 = jet_btag
param5_n3 = delta_R
num_hidden_layers = 2
input_activation_function = selu
hidden_layer_nodes = 40,20
hidden_activation_function = selu
num_output_nodes = 2
output_activation_function = Softmax

[training]
optimizer = nadam
learning_rate = 0.001
num_epochs = 167
beta_1 = 0.9
beta_2 = 0.999
epsilon = 1e-07
loss_function = binary_crossentropy
batch_size = 50

[scaler]
scale_min = 20.000212,20.000214,20.000044,20.000084,20.00003,20.000021,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-3.1415837,-3.1415837,-3.1415837,-3.1415837,-3.1415837,-3.1415837,0.0011739731,0.0011119843,0.0012016296,0.0011634827,0.0011281967,0.0011663437,9.682431,3.679226,0.06251451,0.3871914,0.37924817,0.39628145
scale_max = 1568.3347,1802.4725,1305.9054,1196.0764,860.9007,830.21106,2.4995117,2.4995117,2.4995117,2.4995117,2.4995117,2.4995117,3.1415837,3.1415837,3.1415837,3.1415837,3.1415837,3.1415837,0.9995117,0.9995117,0.9995117,0.9995117,0.9995117,0.9995117,1721.8098,1238.6307,651.7895,5.801419,5.7857795,5.8161626

