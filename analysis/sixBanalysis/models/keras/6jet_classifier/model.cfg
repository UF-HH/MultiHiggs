[model]
input_parameters = 30
param1_n6 = jet_pt
param2_n6 = jet_eta
param3_n6 = jet_phi
param4_n6 = jet_btag
param5_n6 = boosted_pt
num_hidden_layers = 2
input_activation_function = selu
hidden_layer_nodes = 40,20
hidden_activation_function = selu
num_output_nodes = 2
output_activation_function = Softmax

[training]
optimizer = nadam
learning_rate = 0.001
num_epochs = 139
beta_1 = 0.9
beta_2 = 0.999
epsilon = 1e-07
loss_function = binary_crossentropy
batch_size = 50

[scaler]
scale_min = 20.005322,20.003649,20.00003,20.000053,20.000021,20.000044,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-2.4995117,-3.1415837,-3.1415837,-3.1415837,-3.1415837,-3.1415837,-3.1415837,0.007007599,0.0037326813,0.0031738281,0.0025043488,0.0019607544,0.0011119843,0.98899674,0.46442878,0.46181658,0.12519151,0.31305808,0.19229674
scale_max = 1458.1533,1450.4573,1486.7032,1802.4725,1529.801,1750.8777,2.4995117,2.4995117,2.4995117,2.4995117,2.4995117,2.4995117,3.1415837,3.1415837,3.1415837,3.1415837,3.1415837,3.1415837,0.9995117,0.9995117,0.9995117,0.9995117,0.9995117,0.9995117,6327.522,4200.951,5267.997,4336.917,4936.067,4284.317

